# æ–°å¢ï¼švLLM API æœåŠ¡å™¨æµ‹è¯•è„šæœ¬

## ğŸ“ æ¦‚è¿°

æ–°å¢äº† `test_vllm_serve.py` è„šæœ¬ï¼Œç”¨äºæµ‹è¯• vLLM çš„ OpenAI å…¼å®¹ API æœåŠ¡å™¨æ¨¡å¼ã€‚

## âœ¨ åŠŸèƒ½ç‰¹æ€§

### è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹

1. **è‡ªåŠ¨å¯åŠ¨æœåŠ¡å™¨**: ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å¯åŠ¨ vLLM API æœåŠ¡å™¨
2. **ç­‰å¾…æœåŠ¡å™¨å°±ç»ª**: è½®è¯¢å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œæœ€å¤šç­‰å¾… 3 åˆ†é’Ÿ
3. **æ‰§è¡Œ 4 é¡¹æµ‹è¯•**:
   - æŸ¥è¯¢ `/v1/models` - åˆ—å‡ºå¯ç”¨æ¨¡å‹
   - æµ‹è¯• `/v1/completions` - æ–‡æœ¬è¡¥å…¨
   - æµ‹è¯• `/v1/chat/completions` - èŠå¤©å¯¹è¯
   - æµ‹è¯•æµå¼è¾“å‡º - Streaming æ¨¡å¼
4. **è‡ªåŠ¨æ¸…ç†**: æµ‹è¯•å®Œæˆåè‡ªåŠ¨å…³é—­æœåŠ¡å™¨

### æ”¯æŒçš„å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `model` | `facebook/opt-125m` | æ¨¡å‹åç§° |
| `--port` | `8000` | API æœåŠ¡å™¨ç«¯å£ |
| `--gpus` | `1` | GPU æ•°é‡ï¼ˆtensor_parallel_sizeï¼‰|
| `--max-len` | `1024` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--gpu-util` | `0.8` | GPU å†…å­˜ä½¿ç”¨ç‡ |

### è‡ªåŠ¨åŠŸèƒ½

- âœ… **è‡ªåŠ¨ dtype æ£€æµ‹**: æ ¹æ®æ¨¡å‹åç§°é€‰æ‹© float16/bfloat16
- âœ… **è‡ªåŠ¨ç«¯å£ç®¡ç†**: å¯è‡ªå®šä¹‰ç«¯å£é¿å…å†²çª
- âœ… **è‡ªåŠ¨é”™è¯¯å¤„ç†**: æœåŠ¡å™¨å¯åŠ¨å¤±è´¥æ—¶æ˜¾ç¤ºè¯¦ç»†é”™è¯¯
- âœ… **è‡ªåŠ¨èµ„æºæ¸…ç†**: Ctrl+C æˆ–æµ‹è¯•å®Œæˆåè‡ªåŠ¨å…³é—­æœåŠ¡å™¨

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºç¡€ç”¨æ³•

```bash
# è¿›å…¥å®¹å™¨
./host_scripts/enter_vllm_container.sh

# æµ‹è¯•å°æ¨¡å‹
python3 /root/container_scripts/test_vllm_serve.py facebook/opt-125m

# æµ‹è¯• 7B æ¨¡å‹
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct
```

### è‡ªå®šä¹‰é…ç½®

```bash
# ä½¿ç”¨ä¸åŒç«¯å£
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct --port 8080

# å¤š GPU
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct --gpus 2

# å®Œæ•´é…ç½®
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct \
  --port 8000 \
  --gpus 2 \
  --max-len 2048 \
  --gpu-util 0.85
```

### æŸ¥çœ‹å¸®åŠ©

```bash
python3 /root/container_scripts/test_vllm_serve.py --help
```

## ğŸ“Š æµ‹è¯•è¾“å‡ºç¤ºä¾‹

```
============================================================
å¯åŠ¨ vLLM API æœåŠ¡å™¨
============================================================
æ¨¡å‹: facebook/opt-125m
ç«¯å£: 8000
dtype: float16
GPU æ•°é‡: 1
æœ€å¤§åºåˆ—é•¿åº¦: 1024
GPU å†…å­˜ä½¿ç”¨ç‡: 0.8

æ‰§è¡Œå‘½ä»¤: python3 -m vllm.entrypoints.openai.api_server --model facebook/opt-125m ...

â³ å¯åŠ¨æœåŠ¡å™¨ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...
  ç­‰å¾…ä¸­... (10/180 ç§’)
  ç­‰å¾…ä¸­... (20/180 ç§’)
âœ“ æœåŠ¡å™¨å°±ç»ªï¼(45.2 ç§’)

============================================================
å¼€å§‹ API æµ‹è¯•
============================================================

[é¢å¤–] æŸ¥è¯¢å¯ç”¨æ¨¡å‹
  âœ“ æˆåŠŸ
  å¯ç”¨æ¨¡å‹:
    - facebook/opt-125m

[æµ‹è¯• 1/3] Completions API
  âœ“ æˆåŠŸ
  Prompt: Once upon a time
  è¾“å‡º: , there was a young girl named Lucy who lived in a small village...
  Tokens: 50 ç”Ÿæˆ, 55 æ€»è®¡

[æµ‹è¯• 2/3] Chat Completions API
  âœ“ æˆåŠŸ
  User: What is the capital of France?
  Assistant: The capital of France is Paris.
  Tokens: 8 ç”Ÿæˆ, 28 æ€»è®¡

[æµ‹è¯• 3/3] æµå¼è¾“å‡º
  âœ“ æˆåŠŸ
  Prompt: The meaning of life is
  è¾“å‡º:  to find happiness and fulfillment in everything we do.
  Tokens: 15 ä¸ª chunks

============================================================
æµ‹è¯•å®Œæˆ: 4/4 é€šè¿‡
============================================================

æ­£åœ¨å…³é—­æœåŠ¡å™¨...
âœ“ æœåŠ¡å™¨å·²å…³é—­
```

## ğŸ†š å¯¹æ¯”ï¼štest_vllm_auto.py vs test_vllm_serve.py

| ç‰¹æ€§ | test_vllm_auto.py | test_vllm_serve.py |
|------|-------------------|-------------------|
| **æµ‹è¯•æ–¹å¼** | ç›´æ¥è°ƒç”¨ vLLM Python API | é€šè¿‡ HTTP API è°ƒç”¨ |
| **å¯åŠ¨æ—¶é—´** | å¿«ï¼ˆ~30-60ç§’ï¼‰ | è¾ƒæ…¢ï¼ˆ~1-2åˆ†é’Ÿï¼‰|
| **é€‚ç”¨åœºæ™¯** | å¿«é€ŸéªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨ | éªŒè¯ API æœåŠ¡å™¨åŠŸèƒ½ |
| **æµ‹è¯•å†…å®¹** | åŸºç¡€æ¨ç†åŠŸèƒ½ | API ç«¯ç‚¹ã€æµå¼è¾“å‡ºã€èŠå¤© |
| **æœåŠ¡å™¨æ¨¡å¼** | æ—  | å¯åŠ¨å®Œæ•´çš„ HTTP æœåŠ¡å™¨ |
| **ç”¨é€”** | å¼€å‘æµ‹è¯• | ç”Ÿäº§éƒ¨ç½²éªŒè¯ |
| **OpenAI å…¼å®¹** | å¦ | æ˜¯ |

## ğŸ“š æµ‹è¯•çš„ API ç«¯ç‚¹

### 1. GET /health
- **ç”¨é€”**: å¥åº·æ£€æŸ¥
- **è¿”å›**: æœåŠ¡å™¨çŠ¶æ€

### 2. GET /v1/models
- **ç”¨é€”**: åˆ—å‡ºå¯ç”¨æ¨¡å‹
- **è¿”å›**: æ¨¡å‹åˆ—è¡¨ï¼ˆJSONï¼‰

### 3. POST /v1/completions
- **ç”¨é€”**: æ–‡æœ¬è¡¥å…¨
- **å‚æ•°**: prompt, max_tokens, temperature
- **è¿”å›**: ç”Ÿæˆçš„æ–‡æœ¬

### 4. POST /v1/chat/completions
- **ç”¨é€”**: èŠå¤©å¯¹è¯
- **å‚æ•°**: messages, max_tokens, temperature
- **è¿”å›**: åŠ©æ‰‹å›å¤

### 5. POST /v1/completions (stream=true)
- **ç”¨é€”**: æµå¼æ–‡æœ¬ç”Ÿæˆ
- **è¿”å›**: Server-Sent Events (SSE)

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: éªŒè¯æ¨¡å‹éƒ¨ç½²

```bash
# ç¡®è®¤æ¨¡å‹å¯ä»¥ä½œä¸º API æœåŠ¡å™¨è¿è¡Œ
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct
```

### åœºæ™¯ 2: æµ‹è¯•ä¸åŒç«¯å£

```bash
# é¿å…ç«¯å£å†²çª
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct --port 8001
```

### åœºæ™¯ 3: æ€§èƒ½æµ‹è¯•

```bash
# é«˜å†…å­˜é…ç½®
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct \
  --max-len 2048 \
  --gpu-util 0.9
```

### åœºæ™¯ 4: å¤š GPU æµ‹è¯•

```bash
# å¤§æ¨¡å‹å¤š GPU éƒ¨ç½²
python3 /root/container_scripts/test_vllm_serve.py deepseek-ai/DeepSeek-R1-Distill-Llama-70B \
  --gpus 4 \
  --max-len 1024
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ç«¯å£å ç”¨

å¦‚æœç«¯å£ 8000 å·²è¢«å ç”¨ï¼Œä½¿ç”¨ `--port` æŒ‡å®šå…¶ä»–ç«¯å£ï¼š

```bash
python3 /root/container_scripts/test_vllm_serve.py facebook/opt-125m --port 8080
```

### 2. å¯åŠ¨æ—¶é—´

- å°æ¨¡å‹ï¼ˆ< 1Bï¼‰: ~30-60 ç§’
- ä¸­æ¨¡å‹ï¼ˆ3-7Bï¼‰: ~1-2 åˆ†é’Ÿ
- å¤§æ¨¡å‹ï¼ˆ> 13Bï¼‰: ~2-5 åˆ†é’Ÿ

### 3. å†…å­˜ä½¿ç”¨

æœåŠ¡å™¨æ¨¡å¼ä¼šå ç”¨æ›´å¤šå†…å­˜ã€‚å¦‚æœé‡åˆ° OOMï¼Œé™ä½ `--gpu-util`:

```bash
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct --gpu-util 0.6
```

### 4. ä¸­æ–­æµ‹è¯•

æŒ‰ Ctrl+C å¯ä»¥éšæ—¶ä¸­æ–­æµ‹è¯•ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨æ¸…ç†å¹¶å…³é—­æœåŠ¡å™¨ã€‚

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æœåŠ¡å™¨å¯åŠ¨è¶…æ—¶

**ç—‡çŠ¶**: `âœ— æœåŠ¡å™¨å¯åŠ¨è¶…æ—¶ï¼ˆ180 ç§’ï¼‰`

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
- é™ä½ `--max-len` æˆ– `--gpu-util`
- æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦è¶³å¤Ÿ

### é—®é¢˜ 2: ç«¯å£å·²è¢«å ç”¨

**ç—‡çŠ¶**: `Address already in use`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨å…¶ä»–ç«¯å£
python3 /root/container_scripts/test_vllm_serve.py MODEL --port 8001
```

### é—®é¢˜ 3: API æµ‹è¯•å¤±è´¥

**ç—‡çŠ¶**: `âœ— å¤±è´¥: Connection refused`

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®è®¤æœåŠ¡å™¨å·²å¯åŠ¨ï¼ˆçœ‹åˆ° "âœ“ æœåŠ¡å™¨å°±ç»ª"ï¼‰
- æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
- æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—è¾“å‡º

## ğŸ“– ç›¸å…³æ–‡æ¡£

- **ä¸»æ–‡æ¡£**: [README.md](README.md)
- **å®¹å™¨æµ‹è¯•æŒ‡å—**: [docs/guides/CONTAINER_TESTING.md](docs/guides/CONTAINER_TESTING.md)
- **AMD å®˜æ–¹æŒ‡å—**: [docs/guides/AMD_OFFICIAL_VLLM_GUIDE.md](docs/guides/AMD_OFFICIAL_VLLM_GUIDE.md)

## ğŸ‰ æ€»ç»“

`test_vllm_serve.py` æä¾›äº†å®Œæ•´çš„ vLLM API æœåŠ¡å™¨æµ‹è¯•æµç¨‹ï¼š

âœ… **è‡ªåŠ¨åŒ–**: ä»å¯åŠ¨åˆ°å…³é—­å…¨è‡ªåŠ¨
âœ… **å®Œæ•´æµ‹è¯•**: è¦†ç›–æ‰€æœ‰ä¸»è¦ API ç«¯ç‚¹
âœ… **æ˜“äºä½¿ç”¨**: ä¸€æ¡å‘½ä»¤å®Œæˆæ‰€æœ‰æµ‹è¯•
âœ… **OpenAI å…¼å®¹**: æµ‹è¯• OpenAI å…¼å®¹ API
âœ… **ç”Ÿäº§å°±ç»ª**: éªŒè¯ç”Ÿäº§éƒ¨ç½²é…ç½®

ç°åœ¨ä½ å¯ä»¥è½»æ¾éªŒè¯ vLLM ä½œä¸º API æœåŠ¡å™¨çš„åŠŸèƒ½ï¼
