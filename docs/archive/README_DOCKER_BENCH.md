# vLLM Docker Compose åŸºå‡†æµ‹è¯•

ä½¿ç”¨ Docker Compose éƒ¨ç½² vLLM æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯è¿›è¡Œæ€§èƒ½æµ‹è¯•ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
vllm_t/
â”œâ”€â”€ docker-compose.bench.yml          # Docker Compose é…ç½®
â”œâ”€â”€ .env.bench                         # ç¯å¢ƒå˜é‡é…ç½®
â”œâ”€â”€ container_scripts/
â”‚   â””â”€â”€ run_benchmark.sh              # åŸºå‡†æµ‹è¯•è„šæœ¬
â”œâ”€â”€ host_scripts/
â”‚   â””â”€â”€ start_bench_containers.sh     # å®¹å™¨ç®¡ç†è„šæœ¬
â”œâ”€â”€ bench_results/                     # æµ‹è¯•ç»“æœç›®å½•
â”œâ”€â”€ README_DOCKER_BENCH.md            # æœ¬æ–‡æ¡£
â”œâ”€â”€ DOCKER_COMPOSE_MANUAL.md          # è¯¦ç»†ä½¿ç”¨æ‰‹å†Œ
â””â”€â”€ BENCHMARK_QUICK_START.md          # å¿«é€Ÿå¼€å§‹æŒ‡å—
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨å®¹å™¨

```bash
./host_scripts/start_bench_containers.sh
```

### 2. å¯åŠ¨ vLLM æœåŠ¡å™¨

**ç»ˆç«¯ 1**ï¼š
```bash
# è¿›å…¥æœåŠ¡å™¨å®¹å™¨
./host_scripts/start_bench_containers.sh server

# å¯åŠ¨æœåŠ¡å™¨
vllm serve openai/gpt-oss-120b \
  --tensor-parallel-size 4 \
  --dtype bfloat16 \
  --max-model-len 4096 \
  --gpu-memory-utilization 0.8 \
  --enforce-eager
```

### 3. è¿è¡ŒåŸºå‡†æµ‹è¯•

**ç»ˆç«¯ 2**ï¼š
```bash
# è¿›å…¥å®¢æˆ·ç«¯å®¹å™¨
./host_scripts/start_bench_containers.sh client

# è¿è¡Œæµ‹è¯•
/root/container_scripts/run_benchmark.sh
```

---

## ğŸ“‹ å¸¸ç”¨å‘½ä»¤

### å®¹å™¨ç®¡ç†

```bash
# å¯åŠ¨å®¹å™¨
./host_scripts/start_bench_containers.sh

# è¿›å…¥æœåŠ¡å™¨å®¹å™¨
./host_scripts/start_bench_containers.sh server

# è¿›å…¥å®¢æˆ·ç«¯å®¹å™¨
./host_scripts/start_bench_containers.sh client

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
./host_scripts/start_bench_containers.sh ps

# æŸ¥çœ‹æ—¥å¿—
./host_scripts/start_bench_containers.sh logs-server
./host_scripts/start_bench_containers.sh logs-client

# åœæ­¢å®¹å™¨
./host_scripts/start_bench_containers.sh stop

# åˆ é™¤å®¹å™¨
./host_scripts/start_bench_containers.sh down
```

---

## ğŸ¯ åŸºå‡†æµ‹è¯•ç¤ºä¾‹

### é»˜è®¤æµ‹è¯•ï¼ˆæ¨èï¼‰
```bash
/root/container_scripts/run_benchmark.sh
```

### æµ‹è¯•å•ä¸ªå¹¶å‘æ•°
```bash
/root/container_scripts/run_benchmark.sh --single 8
```

### è‡ªå®šä¹‰å¹¶å‘èŒƒå›´
```bash
/root/container_scripts/run_benchmark.sh \
  --min-concurrency 1 \
  --max-concurrency 16 \
  --step 2
```

### è‡ªå®šä¹‰è¾“å…¥è¾“å‡ºé•¿åº¦
```bash
/root/container_scripts/run_benchmark.sh \
  --input-len 512 \
  --output-len 256
```

---

## âš™ï¸ é…ç½®æ–‡ä»¶

### .env.bench

å½“å‰é…ç½®ï¼š
```bash
MODEL_NAME=openai/gpt-oss-120b
DTYPE=bfloat16
GPUS=4
MAX_LEN=1024
GPU_UTIL=0.8
MIN_CLIENTS=1
MAX_CLIENTS=32
STEP=1
DEBUG=false
```

**æ³¨æ„**ï¼šè¿™äº›ç¯å¢ƒå˜é‡ä»…ä¾›å‚è€ƒï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦åœ¨å®¹å™¨å†…æ‰‹åŠ¨æŒ‡å®šå‚æ•°ã€‚

---

## ğŸ“Š æŸ¥çœ‹ç»“æœ

### åœ¨ä¸»æœºä¸Š
```bash
# åˆ—å‡ºç»“æœ
ls -lh bench_results/

# æŸ¥çœ‹ç»“æœ
cat bench_results/results_*.json

# ç¾åŒ–è¾“å‡º
python3 -m json.tool bench_results/results_8_*.json
```

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- **[DOCKER_COMPOSE_MANUAL.md](DOCKER_COMPOSE_MANUAL.md)** - å®Œæ•´ä½¿ç”¨æ‰‹å†Œ
- **[BENCHMARK_QUICK_START.md](BENCHMARK_QUICK_START.md)** - å¿«é€Ÿå¼€å§‹å’Œæ•…éšœæ’æŸ¥

---

## ğŸ—ï¸ æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    vllm-bench-client                    â”‚
â”‚    - è¿è¡ŒåŸºå‡†æµ‹è¯•                        â”‚
â”‚    - å‘é€å¹¶å‘è¯·æ±‚                        â”‚
â”‚    - ä¿å­˜ç»“æœ                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ HTTP (vllm-network)
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    vllm-server                          â”‚
â”‚    - vLLM API æœåŠ¡å™¨                     â”‚
â”‚    - OpenAI å…¼å®¹ API                    â”‚
â”‚    - ç«¯å£: 8000                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ é‡è¦æç¤º

### ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶

`openai/gpt-oss-120b` æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦å–å†³äºä½ å¯åŠ¨æœåŠ¡å™¨æ—¶è®¾ç½®çš„ `--max-model-len`ã€‚

**æ¨èé…ç½®**ï¼š
```bash
--max-model-len 4096    # æ¨èï¼Œå¹³è¡¡æ€§èƒ½å’Œå†…å­˜
```

**æµ‹è¯•æ—¶çš„ token é…ç½®**ï¼š
- ç¡®ä¿ `input_len + output_len < max_model_len`
- é»˜è®¤é…ç½®ï¼š`input=256, output=128` (å®‰å…¨)
- é«˜è´Ÿè½½é…ç½®ï¼š`input=1024, output=512`

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

1. âœ… å¯åŠ¨å®¹å™¨
2. âœ… åœ¨æœåŠ¡å™¨å®¹å™¨ä¸­å¯åŠ¨ vLLM
3. âœ… åœ¨å®¢æˆ·ç«¯å®¹å™¨ä¸­è¿è¡ŒåŸºå‡†æµ‹è¯•
4. âœ… æŸ¥çœ‹ç»“æœå¹¶åˆ†ææ€§èƒ½

**ç¥æµ‹è¯•é¡ºåˆ©ï¼** ğŸš€
