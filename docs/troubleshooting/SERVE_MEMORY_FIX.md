# test_vllm_serve.py å†…å­˜é…ç½®ä¿®å¤

## ğŸ› é—®é¢˜è¯´æ˜

åˆå§‹ç‰ˆæœ¬çš„ `test_vllm_serve.py` ä½¿ç”¨äº†ä¸ `test_vllm_auto.py` ç›¸åŒçš„é»˜è®¤å‚æ•°ï¼ˆ`gpu_util=0.8`, `max_len=1024`ï¼‰ï¼Œä½† vLLM API æœåŠ¡å™¨æ¨¡å¼éœ€è¦**æ›´å¤šé¢å¤–å†…å­˜**æ¥è¿è¡ŒæœåŠ¡å™¨è¿›ç¨‹å’Œé€šä¿¡å¼€é”€ã€‚

### é”™è¯¯ä¿¡æ¯

```
ValueError: Free memory on device (5.31/31.86 GiB) on startup is less than
desired GPU memory utilization (0.8, 25.49 GiB).
Decrease GPU memory utilization or reduce GPU memory used by other processes.
```

**åŸå› **:
- ä½ çš„ GPU å½“å‰åªæœ‰ **5.31 GB** å¯ç”¨å†…å­˜ï¼ˆå¯èƒ½æœ‰å…¶ä»–è¿›ç¨‹å ç”¨ï¼‰
- API æœåŠ¡å™¨æ¨¡å¼é»˜è®¤è¯·æ±‚ 80% (25.49 GB)
- æœåŠ¡å™¨è¿›ç¨‹æœ¬èº«éœ€è¦é¢å¤–çš„å†…å­˜å¼€é”€

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

### 1. é™ä½é»˜è®¤å‚æ•°

å·²å°† `test_vllm_serve.py` çš„é»˜è®¤å€¼è°ƒæ•´ä¸ºï¼š

| å‚æ•° | æ—§å€¼ | æ–°å€¼ | åŸå›  |
|------|------|------|------|
| `--max-len` | 1024 | **512** | å‡å°‘ KV cache å†…å­˜ |
| `--gpu-util` | 0.8 | **0.3** | ä¸ºæœåŠ¡å™¨è¿›ç¨‹é¢„ç•™ç©ºé—´ |

### 2. ä»£ç ä¿®æ”¹

**ä¿®æ”¹ä½ç½® 1**: `VLLMServer.__init__` é»˜è®¤å‚æ•°
```python
# ä¿®æ”¹å‰
def __init__(self, model_name: str, port: int = 8000,
             gpus: int = 1, max_len: int = 1024, gpu_util: float = 0.8):

# ä¿®æ”¹å
def __init__(self, model_name: str, port: int = 8000,
             gpus: int = 1, max_len: int = 1024, gpu_util: float = 0.3):
```

**ä¿®æ”¹ä½ç½® 2**: argparse é»˜è®¤å‚æ•°
```python
# ä¿®æ”¹å‰
parser.add_argument("--max-len", type=int, default=1024, help="æœ€å¤§åºåˆ—é•¿åº¦")
parser.add_argument("--gpu-util", type=float, default=0.8, help="GPU å†…å­˜ä½¿ç”¨ç‡")

# ä¿®æ”¹å
parser.add_argument("--max-len", type=int, default=512, help="æœ€å¤§åºåˆ—é•¿åº¦")
parser.add_argument("--gpu-util", type=float, default=0.3, help="GPU å†…å­˜ä½¿ç”¨ç‡ (0.0-1.0)")
```

---

## ğŸ¯ ä½¿ç”¨å»ºè®®

### åŸºç¡€æµ‹è¯•ï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨æ–°çš„é»˜è®¤å€¼ï¼ˆgpu_util=0.3, max_len=512ï¼‰
python3 /root/container_scripts/test_vllm_serve.py facebook/opt-125m
```

### æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´

**æ£€æŸ¥å¯ç”¨å†…å­˜**:
```bash
# åœ¨å®¹å™¨å†…è¿è¡Œ
rocm-smi

# æˆ–ä½¿ç”¨ Python
python3 -c "import torch; print(f'å¯ç”¨å†…å­˜: {torch.cuda.mem_get_info()[0] / 1024**3:.2f} GB')"
```

**å†…å­˜å……è¶³æ—¶ï¼ˆ> 20 GB å¯ç”¨ï¼‰**:
```bash
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct \
  --gpu-util 0.6 \
  --max-len 1024
```

**å†…å­˜ç´§å¼ æ—¶ï¼ˆ< 10 GB å¯ç”¨ï¼‰**:
```bash
python3 /root/container_scripts/test_vllm_serve.py facebook/opt-125m \
  --gpu-util 0.2 \
  --max-len 256
```

**å†…å­˜éå¸¸ç´§å¼ æ—¶ï¼ˆ< 5 GB å¯ç”¨ï¼‰**:
```bash
# å…ˆæ¸…ç† GPU å†…å­˜
python3 -c "import torch; torch.cuda.empty_cache()"

# ä½¿ç”¨æœ€å°é…ç½®
python3 /root/container_scripts/test_vllm_serve.py facebook/opt-125m \
  --gpu-util 0.15 \
  --max-len 128
```

---

## ğŸ“Š å†…å­˜ä½¿ç”¨å¯¹æ¯”

### test_vllm_auto.pyï¼ˆç›´æ¥ API æ¨¡å¼ï¼‰

| æ¨¡å‹ | max_len | gpu_util | é¢„ä¼°å†…å­˜ |
|------|---------|----------|---------|
| opt-125m | 1024 | 0.8 | ~2 GB |
| Qwen-7B | 1024 | 0.8 | ~15 GB |

### test_vllm_serve.pyï¼ˆæœåŠ¡å™¨æ¨¡å¼ï¼‰

| æ¨¡å‹ | max_len | gpu_util | é¢„ä¼°å†…å­˜ | è¯´æ˜ |
|------|---------|----------|---------|------|
| opt-125m | 512 | 0.3 | ~1 GB | é»˜è®¤é…ç½® âœ… |
| opt-125m | 1024 | 0.5 | ~2.5 GB | éœ€è¦æ›´å¤šå†…å­˜ |
| Qwen-7B | 512 | 0.3 | ~7 GB | ä¿å®ˆé…ç½® |
| Qwen-7B | 1024 | 0.5 | ~16 GB | éœ€è¦å……è¶³å†…å­˜ |

**æœåŠ¡å™¨æ¨¡å¼é¢å¤–å¼€é”€**:
- FastAPI æœåŠ¡å™¨è¿›ç¨‹: ~500 MB
- å¤šè¿›ç¨‹é€šä¿¡: ~200 MB
- è¯·æ±‚ç¼“å†²åŒº: ~300 MB
- **æ€»è®¡é¢å¤–å¼€é”€**: ~1 GB

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: ä»ç„¶å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: å³ä½¿ä½¿ç”¨é»˜è®¤å‚æ•°ä»ç„¶ OOM

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¿›ç¨‹å ç”¨ GPU
rocm-smi

# 2. æ¸…ç† GPU å†…å­˜
python3 -c "import torch; torch.cuda.empty_cache()"

# 3. è¿›ä¸€æ­¥é™ä½å‚æ•°
python3 /root/container_scripts/test_vllm_serve.py facebook/opt-125m \
  --gpu-util 0.15 \
  --max-len 128
```

### é—®é¢˜ 2: æƒ³è¦ä½¿ç”¨æ›´é«˜çš„ gpu_util

**ç—‡çŠ¶**: é»˜è®¤ 0.3 å¤ªä¿å®ˆï¼Œæƒ³æé«˜æ€§èƒ½

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å…ˆç¡®è®¤å¯ç”¨å†…å­˜å……è¶³
python3 -c "import torch; free, total = torch.cuda.mem_get_info(); print(f'å¯ç”¨: {free/1024**3:.2f} GB / æ€»è®¡: {total/1024**3:.2f} GB')"

# å¦‚æœå¯ç”¨å†…å­˜ > 15 GBï¼Œå¯ä»¥æé«˜åˆ° 0.5
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct \
  --gpu-util 0.5

# å¦‚æœå¯ç”¨å†…å­˜ > 25 GBï¼Œå¯ä»¥æé«˜åˆ° 0.7
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct \
  --gpu-util 0.7 \
  --max-len 2048
```

### é—®é¢˜ 3: å…¶ä»–è¿›ç¨‹å ç”¨å†…å­˜

**æ£€æŸ¥å ç”¨**:
```bash
rocm-smi
# æŸ¥çœ‹ "Memory Usage" åˆ—
```

**æ¸…ç†æ–¹æ³•**:
- å…³é—­å…¶ä»–ä½¿ç”¨ GPU çš„ç¨‹åº
- é€€å‡ºæ‰€æœ‰ Python è¿›ç¨‹
- å¦‚æœæ˜¯å®¹å™¨ï¼Œé‡å¯å®¹å™¨

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. å…ˆæµ‹è¯•å°æ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®æµ‹è¯• opt-125m
python3 /root/container_scripts/test_vllm_serve.py facebook/opt-125m
```

### 2. é€æ­¥å¢å¤§æ¨¡å‹å’Œå‚æ•°

```bash
# ç¡®è®¤å°æ¨¡å‹æˆåŠŸåï¼Œæµ‹è¯• 3-4B æ¨¡å‹
python3 /root/container_scripts/test_vllm_serve.py google/gemma-3-4b-it

# å†æµ‹è¯• 7B æ¨¡å‹
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct

# å¦‚æœéœ€è¦æ›´é•¿åºåˆ—ï¼Œé€æ­¥å¢åŠ 
python3 /root/container_scripts/test_vllm_serve.py Qwen/Qwen2-7B-Instruct --max-len 1024
```

### 3. ç›‘æ§å†…å­˜ä½¿ç”¨

åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œï¼š
```bash
watch -n 1 rocm-smi
```

---

## ğŸ†š ä¸¤ç§æ¨¡å¼çš„å†…å­˜é…ç½®

| è„šæœ¬ | é»˜è®¤ gpu_util | é»˜è®¤ max_len | é€‚ç”¨åœºæ™¯ |
|------|--------------|-------------|---------|
| **test_vllm_auto.py** | 0.8 | 1024 | ç›´æ¥æ¨ç†ï¼Œå†…å­˜æ•ˆç‡é«˜ |
| **test_vllm_serve.py** | 0.3 | 512 | API æœåŠ¡å™¨ï¼Œéœ€é¢„ç•™å¼€é”€ |

**å»ºè®®**:
- å¿«é€Ÿæµ‹è¯•ç”¨ `test_vllm_auto.py`
- ç”Ÿäº§éƒ¨ç½²éªŒè¯ç”¨ `test_vllm_serve.py`ï¼ˆè®°å¾—è°ƒæ•´å‚æ•°ï¼‰

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [test_vllm_serve.py ä½¿ç”¨æŒ‡å—](NEW_SERVE_SCRIPT.md)
- [å®¹å™¨æµ‹è¯•æŒ‡å—](docs/guides/CONTAINER_TESTING.md)
- [GPU å‚æ•°è¯´æ˜](GPU_PARAM_UPDATE.md)

---

## ğŸ‰ æ€»ç»“

ä¿®å¤åçš„ `test_vllm_serve.py`:
- âœ… é»˜è®¤å‚æ•°æ›´ä¿å®ˆï¼ˆ`gpu_util=0.3`, `max_len=512`ï¼‰
- âœ… é€‚åˆå†…å­˜å—é™çš„ç¯å¢ƒ
- âœ… å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å‚æ•°
- âœ… ä¸º API æœåŠ¡å™¨æ¨¡å¼é¢„ç•™è¶³å¤Ÿå¼€é”€

ç°åœ¨å¯ä»¥åœ¨å†…å­˜å—é™çš„ç¯å¢ƒä¸‹æˆåŠŸè¿è¡Œ API æœåŠ¡å™¨æµ‹è¯•äº†ï¼
