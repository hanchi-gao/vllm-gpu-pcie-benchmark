# vLLM GPU PCIe é »å¯¬å½±éŸ¿æ¸¬è©¦

åœ¨ AMD GPU (ROCm) ä¸Šæ¸¬è©¦ä¸åŒ PCIe é »å¯¬é…ç½®å° vLLM æ¨è«–æ€§èƒ½çš„å½±éŸ¿ã€‚

> **å°ˆæ¡ˆä¾†æº**: æœ¬å°ˆæ¡ˆå¾ [vllm_t](https://github.com/hanchi-gao/vllm_t) è¤‡è£½è€Œä¾†ï¼Œå°ˆæ³¨æ–¼ GPU PCIe é »å¯¬å° vLLM æ€§èƒ½çš„å½±éŸ¿æ¸¬è©¦ã€‚

**ç¡¬é«”ç’°å¢ƒ**: AMD Radeon AI PRO R9700 (gfx1201)
**Docker æ˜ åƒ**: `rocm/vllm:rocm7.0.0_vllm_0.10.2_20251006`
**vLLM ç‰ˆæœ¬**: 0.10.2

---

## ğŸ“‹ æ¸¬è©¦é…ç½® (æœ€æ–°)

### æ ¸å¿ƒæ¸¬è©¦åƒæ•¸

| åƒæ•¸ | å€¼ | èªªæ˜ |
|------|-----|------|
| **è¼¸å…¥é•·åº¦** | 1024 tokens | å›ºå®šè¼¸å…¥ |
| **è¼¸å‡ºé•·åº¦** | 128 tokens | å›ºå®šè¼¸å‡º |
| **max-model-len** | 1280 tokens | vLLM æœå‹™å™¨è¨­ç½® |
| **num_prompts** | 1-200 | æ¯å€‹é…ç½®æ¸¬è©¦ 200 æ¬¡ |

### ç¡¬é«”é…ç½®å®šç¾©

| é…ç½®ä»£è™Ÿ | æè¿° | PCIe é…ç½® | GPU æ•¸é‡ | å–®å¡é »å¯¬ | æ©Ÿå™¨ä½ç½® |
|---------|------|-----------|---------|---------|---------|
| **A** | æ¶ˆè²»å‹ä¸»æ¿å–®å¡ | 1Ã—x16 | 1 | 32 GB/s | æ©Ÿå™¨ A/B |
| **B** | é›™å¡ x8 é…ç½® | 2Ã—x8 | 2 | 16 GB/s | æ©Ÿå™¨ A/B |
| **C** | å››å¡æ©Ÿé›™å¡ | 2Ã—x16 | 2 | 32 GB/s | æ©Ÿå™¨ C |

**é‡è¦**: é…ç½® A å’Œ B åœ¨åŒä¸€å°æ©Ÿå™¨ä¸Šï¼ˆå¯åˆ‡æ› PCIe è¨­å®šï¼‰ï¼Œé…ç½® C åœ¨å¦ä¸€å°ç¨ç«‹æ©Ÿå™¨ã€‚

### ä½¿ç”¨çš„æ¨¡å‹

| æ¨¡å‹å¤§å° | å®Œæ•´æ¨¡å‹åç¨± | èªªæ˜ |
|---------|-------------|------|
| **7B** | `meta-llama/Llama-3.1-8B` | è¼•é‡ç´šæ¨¡å‹ï¼Œé©åˆåŸºæº–æ¸¬è©¦ |
| **14B** | `Qwen/Qwen3-14B` | ä¸­å‹æ¨¡å‹ï¼Œæ¸¬è©¦ VRAM å£“åŠ› |
| **30B** | `google/gemma-3-27b-it` | å¤§å‹æ¨¡å‹ï¼Œéœ€ TP=2 |

### æ¸¬è©¦çŸ©é™£

#### Machine C (4 å€‹é…ç½® Ã— 200 prompts = 800 å€‹çµæœ)

| æ¸¬è©¦ ID | é…ç½® | æ¨¡å‹ | TP | Input | Output | æè¿° |
|---------|------|------|----|-------|--------|------|
| **1C-1k** | C | 7B | 1 | 1024 | 128 | å–®å¡ baseline |
| **2C-1k** | C | 7B | 2 | 1024 | 128 | x16 ä¸‹ TP é€šè¨Š |
| **3C-1k** | C | 14B | 2 | 1024 | 128 | Qwen æ¨¡å‹æ¸¬è©¦ |
| **4C-1k** | C | 30B | 2 | 1024 | 128 | å¤§æ¨¡å‹æ¸¬è©¦ |

#### Machine A/B (6 å€‹é…ç½® Ã— 200 prompts = 1,200 å€‹çµæœ)

| æ¸¬è©¦ ID | é…ç½® | æ¨¡å‹ | TP | Input | Output | æè¿° |
|---------|------|------|----|-------|--------|------|
| **1A-1k** | A | 7B | 1 | 1024 | 128 | å–®å¡ x16 baseline |
| **1B-1k** | B | 7B | 1 | 1024 | 128 | å–®å¡ x8 å°ç…§ |
| **2B-1k** | B | 7B | 2 | 1024 | 128 | x8 ä¸‹ TP é€šè¨Š |
| **3A-1k** | A | 14B | 1 | 1024 | 128 | å–®å¡ Qwen |
| **4B-1k** | B | 14B | 2 | 1024 | 128 | TP=2 Qwen |
| **5B-1k** | B | 30B | 2 | 1024 | 128 | TP=2 å¤§æ¨¡å‹ |

**ç¸½çµæœæ–‡ä»¶æ•¸**: 2,000 å€‹ JSON æ–‡ä»¶ (10 å€‹é…ç½® Ã— 200 prompts)

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ğŸ—ï¸ å¤šæ©Ÿå™¨æ¸¬è©¦æ¶æ§‹

æœ¬å°ˆæ¡ˆæ”¯æ´å…©ç¨®æ¸¬è©¦æ–¹å¼ï¼š
- **æ©Ÿå™¨ A/B**: é…ç½® A å’Œ B åœ¨åŒä¸€å°æ©Ÿå™¨ï¼ˆ6 å€‹é…ç½®ï¼‰
- **æ©Ÿå™¨ C**: é…ç½® C åœ¨ç¨ç«‹æ©Ÿå™¨ï¼ˆ4 å€‹é…ç½®ï¼‰

æ¨è–¦ä½¿ç”¨**åˆ†æ©Ÿå™¨æ‰¹æ¬¡æ¸¬è©¦è…³æœ¬**ä»¥ç²å¾—æœ€ä½³æ¸¬è©¦é«”é©—ã€‚

---

### é¸é … 1: æ©Ÿå™¨ C æ‰¹æ¬¡æ¸¬è©¦ï¼ˆæ¨è–¦ï¼‰

åœ¨é…ç½® C çš„æ©Ÿå™¨ä¸ŠåŸ·è¡Œæ‰€æœ‰ 4 å€‹æ¸¬è©¦ï¼š

```bash
# 1. å•Ÿå‹• Docker ç’°å¢ƒ
cd docker_setup
docker compose -f docker-compose.bench.yml up -d

# 2. åŸ·è¡Œæ©Ÿå™¨ C çš„æ‰€æœ‰æ¸¬è©¦ï¼ˆå¾å®¹å™¨å¤–ç›´æ¥åŸ·è¡Œï¼‰
docker exec -it vllm-bench-client bash -c "cd /root && ./benchmark_tests/scripts/run_machine_C_tests.sh"

# æˆ–è€…é€²å…¥å®¹å™¨å¾ŒåŸ·è¡Œ
docker exec -it vllm-bench-client bash
cd /root
./benchmark_tests/scripts/run_machine_C_tests.sh
```

**è…³æœ¬æœƒè‡ªå‹•æç¤ºä½ **ï¼š
- ä½•æ™‚éœ€è¦å•Ÿå‹•/é‡å•Ÿ vLLM server
- æ¯çµ„æ¸¬è©¦çš„é€²åº¦
- éœ€è¦ä½¿ç”¨çš„ç¢ºåˆ‡ vLLM å•Ÿå‹•å‘½ä»¤

**æ¸¬è©¦åˆ†çµ„**ï¼š
1. **Group 1**: 7B + TP=1 (1 å€‹æ¸¬è©¦é…ç½® Ã— 200 prompts)
2. **Group 2**: 7B + TP=2 (1 å€‹æ¸¬è©¦é…ç½® Ã— 200 prompts)
3. **Group 3**: 14B (Qwen) + TP=2 (1 å€‹æ¸¬è©¦é…ç½® Ã— 200 prompts)
4. **Group 4**: 30B + TP=2 (1 å€‹æ¸¬è©¦é…ç½® Ã— 200 prompts)

---

### é¸é … 2: æ©Ÿå™¨ A/B æ‰¹æ¬¡æ¸¬è©¦

åœ¨é…ç½® A/B çš„æ©Ÿå™¨ä¸ŠåŸ·è¡Œæ‰€æœ‰ 6 å€‹æ¸¬è©¦ï¼š

```bash
# 1. å•Ÿå‹• Docker ç’°å¢ƒ
cd docker_setup
docker compose -f docker-compose.bench.yml up -d

# 2. åŸ·è¡Œæ©Ÿå™¨ A/B çš„æ‰€æœ‰æ¸¬è©¦ï¼ˆå¾å®¹å™¨å¤–ç›´æ¥åŸ·è¡Œï¼‰
docker exec -it vllm-bench-client bash -c "cd /root && ./benchmark_tests/scripts/run_machine_AB_tests.sh"

# æˆ–è€…é€²å…¥å®¹å™¨å¾ŒåŸ·è¡Œ
docker exec -it vllm-bench-client bash
cd /root
./benchmark_tests/scripts/run_machine_AB_tests.sh
```

**æ¸¬è©¦åˆ†çµ„**ï¼š
1. **Group 1**: 7B + TP=1 (Config A + B, 2 å€‹é…ç½®)
2. **Group 2**: 7B + TP=2 (Config B, 1 å€‹é…ç½®)
3. **Group 3**: 14B (Qwen) + TP=1 (Config A, 1 å€‹é…ç½®)
4. **Group 4**: 14B (Qwen) + TP=2 (Config B, 1 å€‹é…ç½®)
5. **Group 5**: 30B + TP=2 (Config B, 1 å€‹é…ç½®)

---

### é¸é … 3: å–®ä¸€æ¸¬è©¦ï¼ˆæ‰‹å‹•ï¼‰

å¦‚æœä½ æƒ³æ‰‹å‹•åŸ·è¡Œå–®ä¸€æ¸¬è©¦ï¼š

```bash
# é€²å…¥ client å®¹å™¨
docker exec -it vllm-bench-client bash

# åœ¨å¦ä¸€å€‹çµ‚ç«¯å•Ÿå‹• vLLM server
docker exec -it vllm-server bash
vllm serve meta-llama/Llama-3.1-8B \
  --tensor-parallel-size 1 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 1280 \
  --enforce-eager

# å›åˆ° clientï¼ŒåŸ·è¡Œå–®ä¸€æ¸¬è©¦
cd /root
./benchmark_tests/scripts/run_pcie_benchmark.sh --config C --model 7B --tp 1 --input-len 1024
```

**åƒæ•¸èªªæ˜**ï¼š
- `--config`: ç¡¬é«”é…ç½® (A, B, æˆ– C)
- `--model`: æ¨¡å‹å¤§å° (7B, 14B, æˆ– 30B)
- `--tp`: Tensor Parallel å¤§å° (1 æˆ– 2)
- `--input-len`: è¼¸å…¥é•·åº¦ (å›ºå®šç‚º 1024)

---

## ğŸ¯ vLLM Server å•Ÿå‹•å‘½ä»¤åƒè€ƒ

### Group 1: 7B Model + TP=1

```bash
vllm serve meta-llama/Llama-3.1-8B \
  --tensor-parallel-size 1 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 1280 \
  --enforce-eager
```

### Group 2: 7B Model + TP=2

```bash
vllm serve meta-llama/Llama-3.1-8B \
  --tensor-parallel-size 2 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 1280 \
  --enforce-eager
```

### Group 3: 14B (Qwen) Model + TP=2

```bash
vllm serve Qwen/Qwen3-14B \
  --tensor-parallel-size 2 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 1280 \
  --enforce-eager
```

### Group 4: 30B Model + TP=2

```bash
vllm serve google/gemma-3-27b-it \
  --tensor-parallel-size 2 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 1280 \
  --enforce-eager
```

---

## ğŸ“Š çµæœæ–‡ä»¶

### æ–‡ä»¶ä½ç½®

æ‰€æœ‰æ¸¬è©¦çµæœä¿å­˜åœ¨ï¼š
```
bench_results/pcie/
```

### æ–‡ä»¶å‘½åæ ¼å¼

```
{CONFIG}_{MODEL}_{TP}{INPUT}_np{NUM_PROMPTS}_{TIMESTAMP}.json
```

ç¤ºä¾‹ï¼š
- `C_7B_TP1_1k_np1_20251231_120000.json`
- `C_14B_TP2_1k_np100_20251231_120100.json`
- `A_7B_TP1_1k_np200_20251231_120200.json`

### çµæœæ ¼å¼

çµæœæ–‡ä»¶ä½¿ç”¨ vLLM åŸç”Ÿ JSON æ ¼å¼ï¼ˆå–®è¡Œï¼Œç„¡é¡å¤–å…ƒæ•¸æ“šï¼‰ï¼š

```json
{
  "date": "20251231-120000",
  "model_id": "meta-llama/Llama-3.1-8B",
  "num_prompts": 1,
  "request_rate": "inf",
  "duration": 4.30,
  "completed": 1,
  "total_input_tokens": 1024,
  "total_output_tokens": 128,
  "request_throughput": 0.232,
  "output_throughput": 29.74,
  "mean_ttft_ms": 57.65,
  "mean_tpot_ms": 33.43,
  "mean_itl_ms": 33.43,
  ...
}
```

---

## ğŸ”§ è‡ªå®šç¾©æ¸¬è©¦ç¯„åœ

å¦‚æœæƒ³è¦è‡ªå®šç¾© num_prompts çš„æ¸¬è©¦ç¯„åœï¼š

```bash
# åªæ¸¬è©¦ 1-50 å€‹ prompts
NUM_PROMPTS_START=1 NUM_PROMPTS_END=50 \
  ./benchmark_tests/scripts/run_pcie_benchmark.sh --config C --model 7B

# å¿«é€Ÿæ¸¬è©¦ (åªæ¸¬è©¦ 1-3 å€‹ prompts)
NUM_PROMPTS_END=3 \
  ./benchmark_tests/scripts/run_machine_C_tests.sh
```

---

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
vllm-gpu-pcie-benchmark/
â”œâ”€â”€ benchmark_tests/
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ run_pcie_benchmark.sh       # æ ¸å¿ƒæ¸¬è©¦è…³æœ¬
â”‚       â”œâ”€â”€ run_machine_C_tests.sh      # Machine C æ‰¹æ¬¡æ¸¬è©¦
â”‚       â””â”€â”€ run_machine_AB_tests.sh     # Machine A/B æ‰¹æ¬¡æ¸¬è©¦
â”œâ”€â”€ docker_setup/
â”‚   â””â”€â”€ docker-compose.bench.yml        # Docker ç’°å¢ƒé…ç½®
â”œâ”€â”€ bench_results/
â”‚   â””â”€â”€ pcie/                           # æ¸¬è©¦çµæœç›®éŒ„
â””â”€â”€ README.md
```

---

## âš™ï¸ é‡è¦é…ç½®èªªæ˜

### max-model-len è¨­ç½®

- **è¨­å®šå€¼**: 1280 tokens
- **è¨ˆç®—**: 1024 (input) + 128 (output) + 128 (buffer) = 1280
- **æ³¨æ„**: å¦‚æœé‡åˆ° "maximum context length" éŒ¯èª¤ï¼Œè«‹ç¢ºä¿ vLLM server ä½¿ç”¨ `--max-model-len 1280`

### num_prompts èªªæ˜

- æ¯å€‹æ¸¬è©¦é…ç½®æœƒåŸ·è¡Œ 200 æ¬¡ï¼ˆnum_prompts å¾ 1 åˆ° 200ï¼‰
- é€™æ¨£å¯ä»¥æ¸¬è©¦ä¸åŒä¸¦ç™¼ç¨‹åº¦ä¸‹çš„æ€§èƒ½è¡¨ç¾
- çµæœæ–‡ä»¶æ•¸ = æ¸¬è©¦é…ç½®æ•¸ Ã— 200

### Tensor Parallel (TP) èªªæ˜

- **TP=1**: å–® GPU é‹è¡Œï¼Œç„¡è·¨ GPU é€šè¨Š
- **TP=2**: é›™ GPU é‹è¡Œï¼Œæ¸¬è©¦ PCIe é »å¯¬å° GPU é–“é€šè¨Šçš„å½±éŸ¿

---

## ğŸš¨ å¸¸è¦‹å•é¡Œ

### 1. vLLM Server é€£æ¥å¤±æ•—

```bash
# æª¢æŸ¥ server æ˜¯å¦é‹è¡Œ
docker exec vllm-server ps aux | grep vllm

# æª¢æŸ¥ç«¯å£
curl http://vllm-server:8000/health
```

### 2. max-model-len éŒ¯èª¤

å¦‚æœçœ‹åˆ° "maximum context length is 896 tokens" éŒ¯èª¤ï¼š

**åŸå› **: vLLM server å•Ÿå‹•æ™‚æ²’æœ‰æ­£ç¢ºè¨­ç½® `--max-model-len`

**è§£æ±º**: é‡å•Ÿ vLLM serverï¼Œç¢ºä¿ä½¿ç”¨ `--max-model-len 1280`

### 3. VRAM ä¸è¶³

å°æ–¼å¤§æ¨¡å‹ï¼ˆ14B, 30Bï¼‰ï¼Œå¿…é ˆä½¿ç”¨ `--tensor-parallel-size 2`ï¼š

```bash
# âœ“ æ­£ç¢º
vllm serve Qwen/Qwen3-14B --tensor-parallel-size 2 ...

# âœ— éŒ¯èª¤ (VRAM ä¸è¶³)
vllm serve Qwen/Qwen3-14B --tensor-parallel-size 1 ...
```

### 4. æ¸¬è©¦ä¸­æ–·

æ‰¹æ¬¡æ¸¬è©¦è…³æœ¬æ”¯æŒä¸­æ–·æ¢å¾©ï¼š
- å·²å®Œæˆçš„æ¸¬è©¦çµæœæœƒä¿å­˜
- å¯ä»¥å¾å¤±æ•—çš„æ¸¬è©¦çµ„é‡æ–°é–‹å§‹

---

## ğŸ“ˆ ä¸‹ä¸€æ­¥

æ¸¬è©¦å®Œæˆå¾Œï¼š

1. **æ”¶é›†çµæœ**:
   ```bash
   # Machine C
   tar -czf machine_C_results.tar.gz bench_results/pcie/C_*.json

   # Machine A/B
   tar -czf machine_AB_results.tar.gz bench_results/pcie/[AB]_*.json
   ```

2. **åˆä½µçµæœ**: å°‡å…©å°æ©Ÿå™¨çš„çµæœåˆä½µåˆ°åŒä¸€ç›®éŒ„

3. **åˆ†ææ•¸æ“š**: ä½¿ç”¨ Python/Jupyter Notebook åˆ†æ JSON çµæœ

---

## ğŸ“ æ›´æ–°æ—¥èªŒ

### 2025-12-31
- ğŸ”„ å°‡æ¸¬è©¦å¾ request_rate æ”¹ç‚º num_prompts (1-200)
- ğŸ“‰ ç°¡åŒ–æ¸¬è©¦ï¼šåªæ¸¬è©¦ 1024 è¼¸å…¥é•·åº¦
- ğŸ”§ æ›´æ–° max-model-len å¾ 4096 â†’ 1280
- ğŸ¤– å°‡ 14B æ¨¡å‹å¾ Llama-2-13b-hf æ”¹ç‚º Qwen/Qwen3-14B
- ğŸ¤– å°‡ 30B æ¨¡å‹å¾ Llama-2-30b-hf æ”¹ç‚º google/gemma-3-27b-it
- ğŸ“Š çµæœæ–‡ä»¶ä½¿ç”¨ vLLM åŸç”Ÿ JSON æ ¼å¼
- ğŸ› ä¿®å¾©è…³æœ¬å…¼å®¹æ€§å•é¡Œï¼ˆ`set -e` èˆ‡ `((VAR++))`ï¼‰
- ğŸ“ æ¸›å°‘æ¸¬è©¦ç¸½æ•¸ï¼šå¾ 24 å€‹é…ç½® â†’ 10 å€‹é…ç½®

---

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤ Issue æˆ– Pull Requestï¼

## ğŸ“„ æˆæ¬Š

æœ¬å°ˆæ¡ˆéµå¾ªåŸå°ˆæ¡ˆ [vllm_t](https://github.com/hanchi-gao/vllm_t) çš„æˆæ¬Šæ¢æ¬¾ã€‚
